# Robot-Simulation-for-better-UI-Understanding
This project is a java based standalone application that simulates a ROBOT to understand user events, mouse clicks, optimisation of screen looks, scren controls etc.

Robots are supposed to be somewhat autonomous, but most of them can be controlled by some sort of user interface that lets you direct them do to your bidding.  In this project our task is to design an interface to control a simple robot.  We won’t have actual robots, since this is merely an exercise in interface design using the principles we have discussed in class.  The robot has the following capabilities:
1.	It can move forward and backward.  It can also turn in any direction, from 1 degree to 360 degrees, not just left or right.  Once the robot starts to turn it will continue to turn until you tell it not to.  (Turning in this kind of robot usually means making one wheel or tread go faster than the other.)  Obviously it can also stop.  User is  able to tell it to move, to turn, and to stop, and it should respond to our commands immediately.  The fact that it has responded is visible to the user.
2.	It has three speeds: slow, medium, and fast.  
3.	It can be instructed to turn on its camera.  The image seen by the camera is shown, and the image can be resized.  Since We don’t have an actual camera, we simply show some picture I have on the system or from the Web.  
4.	we can request it to send back the current temperature from its temperature sensor. For this, I just generate a random number that is near room temperature.
5.	The robot has a mechanical arm.  You can instruct the arm to move up and down (it has no elbow joint, just a simple continuous motion from 0 degrees (horizontal) to 90 degrees (vertical.)    The arm can also open and close a mechanical claw.  To keep it simple, the claw has two states: open and closed.  The interface reflects the state of the arm and claw.
This is an exercise in design, so we paid careful attention to how  controls are grouped, where they are placed, how obvious their functions are, and how they can be operated with the mouse and/or keyboard.  Given the nature of this interface, full operation from the keyboard is not a requirement.  However, we tried  not to have  much movement of the user’s hands between the mouse and keyboard.  
The screen indicates the current state of the robot.  For example, if it is moving forward at “fast” speed, that will be obvious on the screen.  If the claw is open, that will be obvious.  The position of the mechanical arm can also be known.  If this were a real robot, we would want these things, and we would not assume that, just because we had told it to move forward, it was actually moving.  Thus we simulated a “hardware layer” and not do everything in the user interface.
We used Java Swing and JavaFX, but no third-party controls.
